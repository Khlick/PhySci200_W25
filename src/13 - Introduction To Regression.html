<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8"/>
    <meta content="notranslate" name="google"/>
    <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/>
    <title>
      Introduction To Regression
    </title>
    <link href="lib\favicon.png" rel="icon" type="image/x-icon"/>
    <link href="./src/css/reset.css" rel="stylesheet"/>
    <link href="./src/css/reveal.css" rel="stylesheet"/>
    <link href="./src/css/revealpack.css" rel="stylesheet"/>
    <link href="./src/theme/drG.css" id="theme" rel="stylesheet"/>
    <!-- highlight.js theme -->
    <link href="./src/theme/vs.css" id="highlight-theme" rel="stylesheet"/>
    <!-- Custom CSS -->
    <!-- Custom Scripts -->
    <!-- Print PDF script -->
    <script>
      var link = document.createElement('link');
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match(/print-pdf/gi) ? './src/css/print/pdf.css' : './src/css/print/paper.css';
document.getElementsByTagName('head')[0].appendChild(link);
    </script>
    <!-- Deck CSS Injections -->
    <!-- Deck Script Injections -->
    <!-- Deck Raw Injections -->
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section data-background-image="lib/img/correlation-bg-4.webp" id="deck-title-slide">
          <div class="title-slide background">
            <div class="headline">
              <h2 class="r-fit-text">
                Introduction To Regression
              </h2>
            </div>
            <div class="sub-header">
              <p class="by">
                Khris Griffis, Ph.D.
              </p>
            </div>
            <div class="byline">
              <p class="byinfo">
                PS200 Winter 2025
              </p>
              <p class="byinfo">
                Lecture 13
              </p>
            </div>
          </div>
        </section>
        <section>
          <div class="grid-wrapper">

<div class="header">

<h2>Today's Objectives</h2>

</div>

<div class="content">

<div

class="grid-generic full-width left-justify small"

style="grid-template-columns: 1fr; grid-auto-rows: 1fr; row-gap: 5vmin"

>

<div></div>

<div class="border-bottom fragment" data-fragment-index="1">

<p>

<i class="target"></i> Recap on correlation, introduce information theoretic approach: Mutual Information

</p>

</div>

<div class="border-bottom fragment" data-fragment-index="2">

<p>

<i class="target"></i> Simple Linear Regression

</p>

</div>

<div class="border-bottom fragment" data-fragment-index="2">

<p>

<i class="target"></i> Theoretical approach to parameter estimation

</p>

</div>

<div class="border-bottom fragment" data-fragment-index="3">

<p>

<i class="target"></i> Cautions on using regression

</p>

</div>

<div></div>

</div>

</div>

</div>

<!-- </section> -->
        </section>
        <section data-background-image="lib/img/correlation-bg-6.webp" id="section-title-1">
          <div class="grid-wrapper">
            <div class="section-title-content" id="section-content-1">
              <div class="section-number">
                <span class="large-number">
                  1
                </span>
              </div>
              <div class="headlines">
                <h2 class="r-fit-text">
                  Mutual Information:
                </h2>
                <h3>
                  Correlation Of The 21st Century
                </h3>
              </div>
            </div>
          </div>
          <style>

#section-content-1.section-title-content {

background-color: rgba(240, 240, 240, 0.6) !important;

border-radius: 2rem !important;

box-shadow: 0 0 2rem 2rem rgba(240, 240, 240, 0.6) !important;

}

</style>

<aside class="notes">

<p>Section Notes</p>

</aside>

</section> <!-- End section title -->



<!-- Correlation Introduction -->



<section>

<style>

#cor-left {

width:100%;

align-self:start;

justify-self:end;

}

#cor-left > p {

width:100%;

padding:0;

margin-top: 5px;

margin-bottom: 5px;

text-align:justify;

text-justify: inter-word;

}

</style>

<div class="grid-wrapper">

<div class="header">

<h2>Correlation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:5px;">

<div id="cor-left">

<p>Correlation is a measure of the linear association between two variables.

</p>

<p class="fragment" data-fragment-index="1">

With 2 quantitative variables, we quantify the <span class="info">degree of association</span> as:

</p>

<div class="fragment no-hang big" data-fragment-index=2>

$$r = \frac{\text{Cov}(X,Y)}{\sqrt{s_X^2} \sqrt{s_Y^2}}$$

</div>

<p class="fragment framed" data-fragment-index="3">

The <span class="pop">closer to $\phantom{}\pm1$</span>, the

<span class="em">stronger</span> the <span class="warning">linear</span>

association.

</p>

</div>

<div style="align-self:center;justify-self:center;" class="full-width">

<svg width="100%" viewBox="0 0 720 720">

<use xlink:href="lib/img/correlation-margin-hist.svg#axes_2"></use>

<use xlink:href="lib/img/correlation-margin-hist.svg#axes_3"></use>

<use xlink:href="lib/img/correlation-margin-hist.svg#axes_4"></use>

<use xlink:href="lib/img/correlation-margin-hist.svg#axes_1"></use>

</svg>

</div>

</div>

</div>

</div>

</section>



<!-- Correlation: Limitations -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Correlation: Limitations</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:3fr 2.1fr;grid-auto-rows:auto;gap:2vmin;">

<div class="small left-justify">

<p class="strong danger">Assumptions</p>

<ul>

<li class="emoji-chart fragment" data-fragment-index="1">Both variables must be continuous (interval/ratio)</li>

<li class="emoji-chart fragment" data-fragment-index="1">Linear relationship between variables</li>

<li class="emoji-chart fragment" data-fragment-index="1">Variables should be normally distributed</li>

<li class="emoji-chart fragment" data-fragment-index="1">Equal spread of data points (homoscedasticity)</li>

<li class="emoji-chart fragment" data-fragment-index="1">Independent observations</li>

</ul>

<p class="strong warning fragment" data-fragment-index="2">Limitations</p>

<ul>

<li class="emoji-warning fragment" data-fragment-index="2">Sensitive to outliers</li>

<li class="emoji-warning fragment" data-fragment-index="2">Only detects linear relationships</li>

<li class="emoji-warning fragment" data-fragment-index="2">Does not imply causation</li>

<li class="emoji-warning fragment" data-fragment-index="2">Assumes consistent spread</li>

<li class="emoji-warning fragment" data-fragment-index="2">Affected by measurement errors</li>

<li class="emoji-warning fragment" data-fragment-index="2">Not suitable for categorical data</li>

</ul>

</div>

<div>

<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" viewBox="0 0 425 380" xmlns="http://www.w3.org/2000/svg" version="1.1">

<use xlink:href="lib/img/mi_linear_2.svg#axes_1"></use>

<use xlink:href="lib/img/mi_linear_2.svg#axes_2"></use>

<use xlink:href="lib/img/mi_linear_2.svg#axes_3" class="fragment" data-fragment-index="3"></use>

<use xlink:href="lib/img/mi_linear_2.svg#axes_4" class="fragment" data-fragment-index="3"></use>

</svg>

</div>

</div>

</div>

</div>

</section>



<!-- chi^2 Revisited -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>$\chi^2$ Revisited</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<div>

<p class="left-justify">

Recall, $\chi^2$ is a measure of the <span class="info">association</span> between two categorical variables.

</p>

<p>$\chi^2=\frac{(O-E)^2}{E}$</p>

<p class="fragment" data-fragment-index="1">

That is, we can use $\chi^2$ to test if the distribution of one variable is <span class="pop">predictable</span> across the categories of the other variable.

</p>

<p class="fragment" data-fragment-index="2">

$\chi^2$, or $\chi_{\text{abs}}$, is the total distance (Euclidean or Manhattan) between the observed and expected distributions.

</p>

<p class="fragment info" data-fragment-index="3">

There is a better way!

</p>

</div>

<div class="full-width small">

<div class="grid-generic tiny" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<h3>Observed Values</h3>

<h3>Expected Values</h3>

<table style='border-collapse: collapse; margin: 10px;'><tr><th style='border: 1px solid black; padding: 8px;'></th><th style='border: 1px solid black; padding: 8px;'>Category A</th><th style='border: 1px solid black; padding: 8px;'>Category B</th><th style='border: 1px solid black; padding: 8px;'>Category C</th></tr><tr><td style='border: 1px solid black; padding: 8px;'>Row 1</td><td style='border: 1px solid black; padding: 8px;'>10.00</td><td style='border: 1px solid black; padding: 8px;'>10.00</td><td style='border: 1px solid black; padding: 8px;'>20.00</td></tr><tr><td style='border: 1px solid black; padding: 8px;'>Row 2</td><td style='border: 1px solid black; padding: 8px;'>20.00</td><td style='border: 1px solid black; padding: 8px;'>20.00</td><td style='border: 1px solid black; padding: 8px;'>20.00</td></tr><tr><td style='border: 1px solid black; padding: 8px;'>Row 3</td><td style='border: 1px solid black; padding: 8px;'>30.00</td><td style='border: 1px solid black; padding: 8px;'>30.00</td><td style='border: 1px solid black; padding: 8px;'>20.00</td></tr></table>

<table style='border-collapse: collapse; margin: 10px;'><tr><th style='border: 1px solid black; padding: 8px;'></th><th style='border: 1px solid black; padding: 8px;'>Category A</th><th style='border: 1px solid black; padding: 8px;'>Category B</th><th style='border: 1px solid black; padding: 8px;'>Category C</th></tr><tr><td style='border: 1px solid black; padding: 8px;'>Row 1</td><td style='border: 1px solid black; padding: 8px;'>13.33</td><td style='border: 1px solid black; padding: 8px;'>13.33</td><td style='border: 1px solid black; padding: 8px;'>13.33</td></tr><tr><td style='border: 1px solid black; padding: 8px;'>Row 2</td><td style='border: 1px solid black; padding: 8px;'>20.00</td><td style='border: 1px solid black; padding: 8px;'>20.00</td><td style='border: 1px solid black; padding: 8px;'>20.00</td></tr><tr><td style='border: 1px solid black; padding: 8px;'>Row 3</td><td style='border: 1px solid black; padding: 8px;'>26.67</td><td style='border: 1px solid black; padding: 8px;'>26.67</td><td style='border: 1px solid black; padding: 8px;'>26.67</td></tr></table>

</div>

<p>$\chi^2 = 7.50$, p-value = 0.1117</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>We can think of our quantitative variables as being made up of a bunch of categorical variables. For example, we can bin our quantitative variable into a bunch of categories and then use $\chi^2$ to test if the distribution of one variable is different across the categories of the other variable.</p>

</aside>

</section>



<!-- Kullback-Leibler (KL) Divergence -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Kullback-Leibler (KL) Divergence</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:3.5fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<!-- left -->

<div class="left-justify small">

<p>Information theoretic approach to measuring the difference between two distributions.</p>

<p>Quantifies the expected information gain from using one distribution to approximate another.</p>

<p>KL Divergence is a measure of how one <span class="pop">probability distribution</span> differs from a second, <span class="danger">expected</span> distribution.</p>

<div>

<p>It is a non-symmetric metric, meaning $D_{KL}(P||Q) \neq D_{KL}(Q||P)$.</p>

$$D_{KL}(P||Q) = \sum_{i=1}^{n} P(x_i) \log \frac{P(x_i)}{Q(x_i)}$$

</div>

<p>In terms of entropy, $D_{KL}(P||Q) = H(P,Q) - H(P)$.</p>

<p class="fragment" data-fragment-index="1">

$D_{KL}(O||E) = 0.0204$ ($0.0134$, $0.0861$) <span class="danger">p-value &lt; $10^{-6}$!</span>

</p>

</div>

<!-- right -->

<div>

<img src="lib/img/mi_contingency_example.svg" alt="KL Divergence Example" style="width: 100%;">

</div>

</div>

</div>

</div>

<aside class="notes">

<p>KL divergences tells us how much additional entropy (surprisal) we introduce by using Q to approximate P, versus using P itself.</p>

<p>

The Kullback-Leibler (KL) divergence is a fundamental concept in information theory that measures the difference between two probability distributions. It quantifies the amount of information lost when approximating one distribution with another.

</p>

<p>

In the case of chi squared, we could use the kl divergense to measure the difference between the observed and expected distributions.

</p>

<p>Bits (or nats) are a unit of information. One bit is the amount of information gained by observing a binary variable with two equally likely outcomes. A nat is the amount of information gained by observing a variable with two equally likely outcomes.</p>

<p>H(p) is the entropy of the distribution p, this is the minimum expected number of bits (or nats) needed to encode a sample from P if we use an optimal encoding for P</p>

<p>H(p,q) is the joint/cross entropy of the distributions P and Q. This is the minimum expected number of bits (or nats) needed to encode a sample from P, if we use the encoding scheme optimized for Q.</p>

</aside>

</section>



<!-- Entropy -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Entropy And Mutual Information</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:3fr 1.5fr;grid-auto-rows:auto;gap:1vmin;">

<div>

<ul>

<li class="emoji-lightbulb">

<span class="pop">Entropy</span> is a measure of the uncertainty (<span class="em info">randomness</span>) of a random variable. <span class="fragment em" data-fragment-index="1">Quantifies the amount of information produced by the variable.</span>

</li>

<li class="emoji-lightbulb fragment" data-fragment-index="2">

<span class="pop">$D_{KL}$</span> indicates the expected <span class="em">extra information</span> required to code samples from Y when using coding scheme for X.

</li>

<li class="emoji-lightbulb fragment" data-fragment-index="3">

<span class="pop">Mutual Information</span> is a measure of the amount of information obtained about Y through X. <span class="fragment em" data-fragment-index="4">Quantifies the reduction in uncertainty about Y due to knowledge of X.</span>

</li>

</ul>

</div>

<div>

<img src="lib/img/mi-entropy-venn.png" alt="Entropy and Mutual Information Venn Diagram" style="width: 100%;">

<div class="small no-hang">

$$I(X;Y) = H(X) + H(Y) - H(X,Y)$$

$$I(X;Y) = D_{KL}\left( P(X,Y) || P(X)P(Y) \right)$$

</div>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>As a measure of dependence, mutual information is the amount shared information between two variables.</p>

<p>If X and Y are independent, then P(X,Y) = P(X)P(Y), and therefore KL is 0.</p>

<p>If X and Y are dependent, then P(X,Y) is not equal to P(X)P(Y), and therefore KL is greater than 0.</p>

<p>Mutual information is then the reduction in the uncertainty (surprisal) of Y when X is known, and vice versa.</p>

</aside>

</section>



<!-- Calculating Mutual Information -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Calculating Mutual Information</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:2fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<div class="smallest">

<!-- Steps to calcualte mutual information from X and Y -->

<ol>

<li class="emoji-brain fragment" data-fragment-index="1">

Bin the data<br />

<pre class="language-python"><code data-trim># Compute joint histogram and normalize to probabilities

joint_hist, _, _ = np.histogram2d(x, y, bins=bins)

joint_prob = joint_hist / np.sum(joint_hist)

# Compute marginal probabilities

x_marginal = np.sum(joint_prob, axis=1)

y_marginal = np.sum(joint_prob, axis=0)



# Choose log function based on base

log_func = np.log2 if base == 2 else np.log</code></pre>

</li>

<li class="emoji-brain fragment" data-fragment-index="2">

Calculate the entropy of X and Y<br />

<pre class="language-python"><code data-trim># Calculate entropies, using masked arrays to handle log(0)

h_x = -np.sum(x_marginal[x_marginal > 0] *

&nbsp;&nbsp;&nbsp;&nbsp;log_func(x_marginal[x_marginal > 0]))

h_y = -np.sum(y_marginal[y_marginal > 0] *

&nbsp;&nbsp;&nbsp;&nbsp;log_func(y_marginal[y_marginal > 0]))</code></pre>

</li>

<li class="emoji-brain fragment" data-fragment-index="3">

Calculate the joint entropy of X and Y<br />

<pre class="language-python"><code data-trim>mask = joint_prob > 0

h_joint = -np.sum(joint_prob[mask] * log_func(joint_prob[mask]))</code></pre>

</li>

<li class="emoji-brain fragment" data-fragment-index="4">

Calculate the mutual information<br />

<pre class="language-python"><code data-trim>

mi = h_x + h_y - h_joint</code></pre>

</li>

</ol>

<p class="fragment smaller danger" data-fragment-index="5">

Mutual Information is sensitive to the choice of bin size and method of discretization.

</p>

<p class="fragment em smaller success" data-fragment-index="6">

Use <span class="as-code">sklearn.feature_selection.mutual_info_regression</span> to employ a <span class="strong">KNN</span> approach!

</p>

</div>

<div style="align-self:center;justify-self:center;justify-content: center;align-items: center;height:100%;" class="fragment" data-fragment-index="1">

<img src="lib/img/circleScatterPlotMICij.svg" alt="Circle Scatter Plot of Mutual Information" style="height: 100%;">

</div>

</div>

</div>

</div>

</section>



<!-- Comparing Methods -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Comparing Methods</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:5vmin;width:90%;">

<div>

<h4 class="muted">KNN Method (unbinned)</h4>

<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" viewBox="0 0 640 640" xmlns="http://www.w3.org/2000/svg" version="1.1">

<use xlink:href="lib/img/mi-cor-comparison-knn.svg#axes_1" class="fragment" data-fragment-index="1"></use>

<use xlink:href="lib/img/mi-cor-comparison-knn.svg#axes_2" class="fragment" data-fragment-index="2"></use>

<use xlink:href="lib/img/mi-cor-comparison-knn.svg#axes_3" class="fragment" data-fragment-index="3"></use>

<use xlink:href="lib/img/mi-cor-comparison-knn.svg#axes_4" class="fragment" data-fragment-index="4"></use>

</svg>

</div>

<div>

<h4 class="muted">Entropy Method (binned)</h4>

<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100%" viewBox="0 0 640 640" xmlns="http://www.w3.org/2000/svg" version="1.1">

<use xlink:href="lib/img/mi-cor-comparison-entropy.svg#axes_1" class="fragment" data-fragment-index="1"></use>

<use xlink:href="lib/img/mi-cor-comparison-entropy.svg#axes_2" class="fragment" data-fragment-index="2"></use>

<use xlink:href="lib/img/mi-cor-comparison-entropy.svg#axes_3" class="fragment" data-fragment-index="3"></use>

<use xlink:href="lib/img/mi-cor-comparison-entropy.svg#axes_4" class="fragment" data-fragment-index="4"></use>

</svg>

</div>

</div>

</div>

</div>

</section>



<!-- Bootstrapping -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Bootstrapping</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<div style="justify-content: center;">

<img src="lib/img/mi_ci95_boot.png" alt="95% CI of Mutual Information" class="framed graphic" style="height:100%;">

</div>

<div style="justify-content: center;">

<img src="lib/img/mi_nhst_boot.png" alt="Null hypothesis testing of Mutual Information" class="framed graphic" style="height:100%;">

</div>

</div>

</div>

</div>

<aside class="notes">

<p>Same Process as correlation, for a 95% ci, resample the rows, for NHST break the rows.</p>

</aside>

<!-- </section> -->
        </section>
        <section data-background-image="lib/img/correlation-bg-5.webp" data-background-size="cover" id="section-title-2">
          <div class="grid-wrapper">
            <div class="section-title-content" id="section-content-2">
              <div class="section-number">
                <span class="large-number">
                  2
                </span>
              </div>
              <div class="headlines">
                <h2 class="r-fit-text">
                  Linear Regression
                </h2>
              </div>
            </div>
          </div>
          <style>

#section-content-2.section-title-content {

background-color: rgba(240, 240, 240, 0.6) !important;

border-radius: 2rem !important;

box-shadow: 0 0 2rem 2rem rgba(240, 240, 240, 0.6) !important;

}

</style>

<aside class="notes">

<p>Section Notes</p>

</aside>

</section> <!-- End section title -->



<!-- Why would we want to? -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>What Is The Purpose of Correlation?</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1.25fr 8fr;grid-auto-rows:1fr;gap:5px;justify-content:center;">

<div style="grid-column:1/2;grid-row:1/2;align-self:center;">

<img class="framed" src="lib/img/regression-ex-forensic.jpg" width=100%>

</div>

<div style="grid-column:2/3;grid-row:1/2;align-self:center;text-align:left;">

<p class="small">

<span class="u em danger">Forensic analysis:</span>

Most people are not accustomed to looking at foot length, so describing the suspect as having a foot of 10.5inches long would probably not help find the suspect. It would be <span class="info">far more useful</span> to tell people to look for a <span class="u-info">suspect who is of a certain <span class="info">height</span></span>.

</p>

<p class="fragment" data-fragment-index=3>

<i class="fas fa-arrow-circle-right danger"></i>

The accuracy of this prediction would depend on the size of the <span class="u-danger">correlation between foot length and height</span>

</p>

</div>

<div style="grid-column:1/2;grid-row:2/3;align-self:center;">

<img class="framed" src="lib/img/regression-ex-anthropology.jpeg" width=100%>

</div>

<div style="grid-column:2/3;grid-row:2/3;align-self:center;text-align:left;">

<p class="small">

<span class="u em danger">Anthropology:</span>

Body proportions and the dimensions of various body segments,

including the long bones of their limbs and the bones of the

foot and hand have been used to <span class="info">estimate stature</span>.

</p>

<p class="fragment" data-fragment-index=3>

<i class="fas fa-arrow-circle-right danger"></i>

The accuracy of this prediction would depend on the size of the <span class="u-danger">correlation between foot length and height</span>

</p>

</div>

</div>

</div>

</div>

</section>



<!-- Going beyond -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Limitations Of Correlation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:3.4fr 6.5fr;grid-auto-rows:auto;gap:5px;">

<div style="grid-column:1/3;grid-row:1/2;">

<p>

Because the correlation coefficient only gives information about

the

<span class="danger">direction</span> and

<span class="danger">strength</span> of an association,

we cannot use it

directly to get information of someone's height from

their footprint.

</p>

</div>

<div style="grid-column:1/2;grid-row:2/3;">

<svg width="100%" viewBox="340 0 295 288">

<use xlink:href="lib/img/correlation-simulation-graph-swap.svg#axes_2"></use>

<use class="fragment" data-fragment-index=2 xlink:href="lib/img/correlation-simulation-graph-swap.svg#axes_5"></use>

<use class="fragment" data-fragment-index=3 xlink:href="lib/img/correlation-simulation-graph-swap.svg#axes_6"></use>

</svg>

</div>

<div style="grid-column:2/3;grid-row:2/3;display:grid;row-gap:2vmin;">

<p class="framed border-pop">

If we decide the association is linear (<span class="em">strong $r$</span>), it is useful to

<span class="pop">develop a mathematical model</span>

of that association.

</p>

<p class="smaller fragment" data-fragment-index="2">

<i class="fas fa-arrow-circle-right orange"></i>

The process of fitting a line to a set of data is called <span class="orange em">linear regression</span>, and the line

of best fit is called the <span class="orange em">regression line</span>, which is the line that gets as close as possible

to all of the data points.

</p>

<p class="smaller fragment" data-fragment-index="3">

<i class="fas fa-arrow-circle-right danger"></i>

We can use the regression line to give a <span class="danger">predicted value of the response variable</span>, based on a given value of the explanatory variable.

</p>

</div>

</div>

</div>

</div>

</section>



<section>

<div class="grid-wrapper">

<div class="header">

<h2>Linear Regression Analysis</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<p>

Linear regression analysis consists of <span class="info">more than

just fitting a linear line</span> through a cloud of data points. The linear regression analysis of a dataset can be

decomposed in <span class="info">3 stages</span>:

</p>

<ol class="small down-3">

<li>

<span class="u strong">Analyzing</span> the correlation and directionality of the data (checking if linear

regression is an <span class="danger">appropriate model</span> for the data you want to analyze)

</li>

<li>

<span class="u strong">Estimating</span> the model using the data (fitting the line, estimating the

<span class="danger">best parameters</span> for the line equation)

</li>

<li>

<span class="u strong">Evaluating</span> the <span class="danger">validity and usefulness</span> of the model

</li>

</ol>

</div>

</div>

</div>

</section>



<!-- Major Uses of Linear Regression -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Linear Regression Uses</h2>

</div>

<div class="content">

<div class="grid-generic smaller" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:1vmin;">

<p class="framed border-pop left-justify fragment">

<span class="pop em u strong">Causal Analysis</span>: Regression can be used to <span class="strong">quantify the relationship</span> between one or more <span class="em">independent variables</span> and a <span class="em">dependent variable</span>. It helps in understanding how changes in the <span class="u">independent variables</span> are associated with changes in the <span class="u">dependent variable</span>. A key point is that <span class="strong">correlation does not imply causation</span>, and additional analysis or experimentation is often required to <span class="em">establish causal relationships</span>.

<br>

<span class="pop">Example question</span>: "How does an additional year of education impact a person's income?"

</p>

<p class="framed border-info left-justify fragment">

<span class="info em u strong">Estimation</span>: Regression can be used to <span class="strong">estimate the specific value</span> of the <span class="em">dependent variable</span> given certain values of the <span class="em">independent variable(s)</span>. This is particularly useful in fields where <span class="u">precise measurements</span> are necessary.

<br>

<span class="info">Example question</span>: "What is the life expectancy of a person who has smoked $X_1$ pack(s) of cigarettes per day for $X_2$ years?"

</p>

<p class="framed border-danger left-justify fragment">

<span class="danger em u strong">Forecasting</span>: While similar to <span class="em">prediction</span>, forecasting specifically refers to <span class="strong">estimating values over time</span>. Regression can be used to <span class="u">model trends</span> and <span class="strong">forecast future values</span> based on historical data, acknowledging that forecasts are always subject to <span class="em">uncertainty</span>.

<br>

<span class="danger">Example question</span>: "What is the predicted incidence rate of hospital-acquired infections (HAIs) in the next quarter, given historical trends, seasonal variations, and changes in hospital protocols?"

</p>

<p class="smaller muted right-justify fragment">We should always be very cautious of <span class="em">extrapolating</span> beyond the domain of our data.</p>

</div>

</div>

</div>

<!-- </section> -->
        </section>
        <section>
          <!-- A Linear "Model" -->

<div class="grid-wrapper">

<div class="header">

<h2>A Linear <span class="s-quote">Model</span></h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1.5fr;grid-template-rows:1fr;gap:1vmin;">

<div style="font-size:80%;text-align:left;justify-items:start;align-items:center;display:grid;gap:2vmin;">

<p>

<span class="u em">Linear regression model:</span>

</p>

<p class="big">

$\hat{y}=\beta_0+\beta_1x$

</p>

<p>

Find the <span class="quoted">Best fit line</span>

</p>

<p class="fragment" data-fragment-index="1">

Find the line ($\hat{y}$) that minimizes the distance between the measured response, $y_i$, and the predicted predicted response, $\hat{y}_i$.

</p>

<p class="fragment" data-fragment-index="2">

<span class="em strong">Terminology:</span> This <span class="s-quote">distance</span> is called a <span class="u">residual</span>. <br />

Defined as: $\epsilon_i = y_i - \hat{y}_i$.

</p>

<p class="fragment" data-fragment-index="3">

How might you go about finding this line?

</p>

</div>

<vizzy data-src="lib/interactives/linear-regression"></vizzy>

</div>

</div>

</div>

<aside class="notes">

<p>Think about how we calculate variance, what happens to the sum of the residuals when we find the best fit line? They sum to zero.</p>

</aside>

</section>





<!-- The regression line -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>The Regression Line</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:3.5fr 6.5fr;grid-auto-rows:auto;gap:5px;">



<p style="grid-column:1/3;grid-row:1/2;">

To make predictions, we use the <span class="info">equation of the regression line</span>.

</p>



<div style="grid-column:1/3;grid-row:2/3;grid-template-columns:4fr 6fr;grid-auto-rows:auto;gap:5vmin;" class="grid-generic box-width">

<div>

<svg width="100%" viewBox="0 0 360 360">

<use xlink:href="lib/img/regression-line.svg#axes_1"></use>

<use xlink:href="lib/img/regression-line.svg#axes_2" class="fragment" data-fragment-index="1"></use>

<use xlink:href="lib/img/regression-line.svg#axes_3" class="fragment" data-fragment-index="2"></use>

</svg>

</div>

<div style="display:grid;gap:2vmin;align-self:center;align-items:center;">

<p class="fragment" data-fragment-index="0">

<span class="u em">Equation for a line:</span> <br>

$y= \beta_0 + \beta_1x$

</p>

<div>

<p class="fragment" data-fragment-index="1">

<span class="warning">$\beta_0$</span>: y-intercept at $x=0$

</p>

<p class="fragment" data-fragment-index="2">

<span class="success">$\beta_1$</span>: slope of the line (often called <span class="success">$m$</span>)

</p>

<p class="left-justify fragment" data-fragment-index="3">

<i class="fas fa-arrow-circle-right danger"></i>

Predicting the response variable from the explanatory

variable:

</p>

<p class="fragment" data-fragment-index="3">

<span class="danger">$\mathrm{Response}= \beta_0 + \beta_1 \times \mathrm{Explanatory}$</span>

</p>

</div>

</div>

</div>

<div style="grid-column:1/3;grid-row:3/4;" class="fragment small no-hang" data-fragment-index="3">

<p>You can imagine extending this to multiple explanatory variables:</p>

$$

\hat{y}=\beta_0+\beta_1X_1+\beta_2X_2+\cdots+\beta_nX_n

$$

</div>

</div>

</div>

</div>

</section>



<!-- The Linear Parameters -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>The Regression "Line"</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;row-gap:5vmin;justify-items:start;width:80%;">

<p style="justify-self:start;">

<i class="fas fa-arrow-circle-right danger"></i>

When used to make prediction, the equation of the regression line is written:

</p>

<div class="grid-generic" style="grid-template-columns:2fr 8fr;grid-template-rows:1fr;gap:5px;">

<p style="align-self:center;">

$\hat{y}=\beta_0+\beta_1x$

</p>

<div style="text-align:left;margin-left:15px;">

<p>

<span class="danger">$x$</span>: value of the explanatory variable

</p>

<p>

<span class="danger">$\hat{y}$</span>: predicted value of the response variable

</p>

</div>

</div>

<p class="fragment">

<i class="fas fa-arrow-circle-right info"></i>

For a given data set, the signs (positive, negative, or zero) for the correlation coefficient and the slope of the regression line must be the same.

</p>

<p class="fragment">

<i class="fas fa-arrow-circle-right orange"></i>

The slope of the regression line can be interpreted as the <span class="u-orange">predicted change in the <span class="orange strong">average response variable</span> for a one-unit change in the explanatory variable</span>.

</p>

</div>

</div>

</div>

</section>



<!-- HOW DOES REGRESSION WORK? -->

<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2>How Does Linear Regression Work?</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<div>

<svg width="100%" viewBox="0 0 360 340">

<use xlink:href="lib/img/regression-least-square.svg#axes_1"></use>

<use class="fragment" data-fragment-index=1 xlink:href="lib/img/regression-least-square.svg#axes_3"></use>

</svg>

</div>

<div style="align-self:center;">

<p class="fragment" data-fragment-index=1>

The vertical distance from a data point to the regression

line is called a <span class="danger">residual</span>.

</p>

<p class="fragment" data-fragment-index=2>

$\mathrm{Residual} = \mathrm{Observed} - \mathrm{Predicted}$

$\mathrm{Residual} = y_i - \hat{y}$

</p>

</div>

</div>

</div>

</div>

</section>



<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2>How Does Linear Regression Work?</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<div>

<svg width="100%" viewBox="0 0 360 340">

<use xlink:href="lib/img/regression-least-square.svg#axes_1"></use>

<use xlink:href="lib/img/regression-least-square.svg#axes_3"></use>

</svg>

</div>

<div style="align-self:center;">

<svg width="100%" viewBox="0 0 432 180">

<use xlink:href="lib/img/regression-residuals.svg#axes_1"></use>

</svg>

<ul class="small">

<li role="fa" data-icon="&#xf30c;" class="success">Points above the regression line

<ul class="black">

<li class="emoji-arrowr"><span class="success">positive</span> residuals</li>

</ul>

</li>

<li role="fa" data-icon="&#xf309;" class="danger">Points below the regression line

<ul class="black">

<li class="emoji-arrowr"><span class="danger">negative</span> residuals</li>

</ul>

</li>

<li role="fa" data-icon="&#xf140;">If the predicted values closely match the observed data values, the residuals will be <span class="orange">small</span>.</li>

</ul>

</div>

<div style="grid-column:1/3;">

<p class="small">

<i class="fas fa-arrow-circle-right pink"></i> The line that fits the data best is the one where the residuals are close to zero.

</p>

</div>

</div>

</div>

</div>

</section>



<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2>How Does Linear Regression Work?</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:1vmin;">

<div>

<svg width="100%" viewBox="0 0 360 340">

<use xlink:href="lib/img/regression-least-square.svg#axes_1"></use>

<use xlink:href="lib/img/regression-least-square.svg#axes_3"></use>

<use class="fragment" data-fragment-index=1 xlink:href="lib/img/regression-least-square.svg#axes_2"></use>

</svg>

</div>

<div style="align-self:center;">

<svg width="100%" viewBox="0 0 432 180">

<use xlink:href="lib/img/regression-residuals.svg#axes_1"></use>

</svg>

<p>

<i class="fas fa-arrow-circle-right pink"></i>

Instead of working directly with the residuals, we usually try to <span class="pink">minimize the sum of the

square of the residuals</span>:

</p>

<p>

$SS_{residuals}=\sum_{i=1}^{n}(y_i-\hat{y_i})^2$

</p>

</div>

</div>

</div>

</div>

</section>



<!-- Notes on minimizing sse 1 -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Minimizing $SS_{\mathrm{residuals}}$ (aka $SSE$)</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:6fr 4fr;grid-auto-rows:auto;gap:1vmin;">

<p style="grid-column:1/2;">

<i class="fas fa-arrow-circle-right info"></i>

The errors (residuals) are squared to prevent the positive and negative errors to cancel out each

others, which could give you a value of zero.

</p>

<p class="grid-column:2/3;">

$SS_{residuals}=\sum_{i=1}^{n}(y_i-\hat{y_i})^2$

</p>

<div style="grid-column:1/3;">

<p class="fragment" data-fragment-index="1">

<i class="fas fa-arrow-circle-right danger"></i>

Most statistical software packages use a procedure called

<span class="danger">Ordinary Least Squares (OLS)</span> to find

the line of best fit. This procedure finds a line that minimizes

the sum of the squared errors.

</p>

</div>

<div style="grid-column:1/2;">

<p class="fragment" data-fragment-index="2">

<i class="fas fa-arrow-circle-right pop"></i>

While OLS is pretty much the standard, different penalty functions can be use as well. For example,

the <span class="pop">Median Absolute Deviation (MAD)</span> uses the absolute error, and so will

be more <span class="u-orange">robust to outliers</span> since it assigns less weight to outliers than OLS.

</p>

</div>

<div class="fragment" data-fragment-index="2" style="grid-column:2/3;width:80%;">

<svg width="100%" viewBox="0 0 360 360">

<use xlink:href="lib/img/regression-least-square-vs-mad.svg#axes_1"></use>

</svg>

</div>

</div>

</div>

</div>

</section>



<!-- Notes on minimizing sse 2 -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Minimizing $SS_{\mathrm{residuals}}$ (aka $SSE$)</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:6fr 4fr;grid-auto-rows:auto;gap:1vmin;">

<p style="grid-column:1/2;">

<i class="fas fa-arrow-circle-right info"></i>

The errors (residuals) are squared to prevent the positive and negative errors to cancel out each

others, which could give you a value of zero.

</p>

<p class="grid-column:2/3;">

$SS_{residuals}=\sum_{i=1}^{n}(y_i-\hat{y_i})^2$

</p>

<div style="grid-column:1/3;">

<p>

<i class="fas fa-arrow-circle-right danger"></i>

Most statistical software packages use a procedure called

<span class="danger">Ordinary Least Squares (OLS)</span> to find

the line of best fit. This procedure finds a line that minimizes

the sum of the squared errors.

</p>

</div>

<div style="grid-column:1/2;">

<p>

<i class="fas fa-arrow-circle-right pop"></i>

While OLS is pretty much the standard, different penalty functions can be use as well. For example,

the <span class="pop">Median Absolute Deviation (MAD)</span> uses the absolute error, and so will

be more <span class="u-orange">robust to outliers</span> since it assigns less weight to outliers than OLS.

</p>

</div>

<div style="grid-column:2/3;width: 80%;">

<svg width="100%" viewBox="0 0 360 360">

<use xlink:href="lib/img/regression-least-square-vs-mad-fit.svg#axes_1"></use>

<use class="fragment" xlink:href="lib/img/regression-least-square-vs-mad-fit.svg#axes_2"></use>

</svg>

</div>

</div>

</div>

</div>

<!-- </section> -->
        </section>
        <section>
          <!-- Setup -->

<!-- <section> -->

<div class="grid-wrapper">

<div class="header">

<h2>Determining Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-template-rows:1fr;gap:5px;">

<div style="font-size:80%;">

<p>

Given the system: \(\mathrm {X} {\boldsymbol {\beta }}=\mathbf {y} ,\) where



\[{\displaystyle \mathrm {X} ={\begin{bmatrix}X_{11}&X_{12}&\cdots &X_{1p}\\X_{21}&X_{22}&\cdots &X_{2p}\\\vdots &\vdots &\ddots &\vdots \\X_{n1}&X_{n2}&\cdots &X_{np}\end{bmatrix}},\qquad {\boldsymbol {\beta }}={\begin{bmatrix}\beta _{1}\\\beta _{2}\\\vdots \\\beta _{p}\end{bmatrix}},\qquad \mathbf {y} ={\begin{bmatrix}y_{1}\\y_{2}\\\vdots \\y_{n}\end{bmatrix}}.}\]

</p>

<p>

The estimated solution is: \({\displaystyle {\hat {\boldsymbol {\beta }}}=(\mathbf {X} ^{\mathsf {T}}\mathbf {X} )^{-1}\mathbf {X} ^{\mathsf {T}}\mathbf {y} .}\)

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>These are estimates!</p>

</aside>

</section>

<!-- Setup 2 -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Determining Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-template-rows:1fr;gap:5px;font-size:90%;">

<div style="text-align:left;">

<p>

Consider the model: $\begin{align}

Y = \beta_0+\beta_1 X +\epsilon,

\end{align}$

</p>

<p>

where $\epsilon$ is a $\mathcal{N}(0,\sigma^2)$ random variable independent of $X$.

We can determine the $\beta$ coefficients by first taking the <span class="em">Expected Value</span>

from both sides and rearranging the equation:

$$\begin{align} %

\mathbb{E}Y &= \beta_0+\beta_1 \mathbb{E}X +\mathbb{E}[\epsilon]\\

&=\beta_0+\beta_1 \mathbb{E}X\\

\beta_0&=EY-\beta_1 EX.

\end{align}$$

</p>

</div>

<div style="text-align:left;">

<p>

For $\beta_1$, we turn to $\textrm{Cov}(X,Y)$ where

</p>

<p>

$\begin{align}

\textrm{Cov}(X,Y) &= \textrm{Cov}(X,\beta_0+\beta_1 X +\epsilon)\\

&=\beta_0 \textrm{Cov}(X,1)+\beta_1\textrm{Cov}(X,X)+\textrm{Cov}(X, \epsilon)\\

&=0+\beta_1 \textrm{Cov}(X,X)+0 \quad (\textrm{since $X$ and $\epsilon$ are independent})\\

&=\beta_1 \textrm{Var}(X)\\

\therefore\beta_1&=\frac{\textrm{Cov}(X,Y)}{\textrm{Var}(X)}

\end{align}$

</p>

<p class="framed border-success">

$$\begin{align}

&\hat{\beta_1}=\frac{s_{xy}}{s_{xx}},\\

&\hat{\beta_0}=\overline{y}-\hat{\beta_1} \overline{x}.

\end{align}$$

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>These are estimates!</p>

</aside>

</section>



<section>

<div class="grid-wrapper">

<div class="header">

<h2>Derivation of Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic no-hang" style="grid-template-columns: repeat(2, 1fr); grid-auto-rows: auto; gap: 1vmin;">

<div class="no-hang pad-bottom fragment" data-fragment-index="1">

<p><i class="info huge" role="emoji" data-emoji="&#x2776;"></i></p>

<p class="small">The error in the ith observation is:</p>

<div class="smaller">$$\epsilon_i = y_i - \hat{y_i} = y_i - (\hat{\beta}_0 + \hat{\beta}_1x_i) $$</div>

<p class="smaller">(Observed - Predicted)</p>

</div>

<div class="no-hang pad-bottom fragment" data-fragment-index="3">

<p><i class="info huge" role="emoji" data-emoji="&#x2778;"></i></p>

<p class="small">Setting mean error to zero, we obtain:</p>

<div class="smaller">$$ \hat{\beta}_0 = \bar{y} - \hat{\beta}_1\bar{x} $$</div>

</div>

<div class="no-hang pad-bottom fragment" data-fragment-index="2">

<p><i class="info huge" role="emoji" data-emoji="&#x2777;"></i></p>

<p class="small">For a sample of n observations, the mean error is:</p>

<div class="smallest">$$ME = \bar{\epsilon} = \frac{1}{n} \sum \epsilon_i = \frac{1}{n} \sum \left[ y_i - (\hat{\beta}_0 + \hat{\beta}_1x_i) \right]$$</div>

<div class="smaller">$$ = \bar{y} - \hat{\beta}_0 - \hat{\beta}_1\bar{x} $$</div>

</div>

<div class="no-hang pad-bottom fragment" data-fragment-index="4">

<p><i class="info huge" role="emoji" data-emoji="&#x2779;"></i></p>

<p class="small">Substituting $\hat{\beta}_0$ in the error expression, we get:</p>

<div class="smaller">$$ \epsilon_i = y_i - \bar{y} + \hat{\beta}_1(\bar{x} - x_i) $$</div>

<p class="smallest">(Error term for each observation after substituting $\beta_0$)</p>

</div>

<div class="small framed border-success full-width fragment" style="grid-column:1/3;" data-fragment-index="5">

<p>

The derivation begins by defining the <span class="em">error for each data point</span>

and setting the average error to zero,

which leads to an expression for the intercept, \(\hat{\beta}_0\),

in terms of the mean values of \(y\) and \(x\) and the

slope, \(\hat{\beta}_1\).

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

Note: This step assumes that the mean of the residuals (errors) is zero,

which is a property of the least squares regression.

</p>

</aside>

</section>



<!-- Slide 2: Continuation of Derivation of Regression Parameters -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Derivation of Coefficients</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns: repeat(2, 1fr); grid-auto-rows:auto; gap: 1vmin;">

<div class="no-hang">

<p class="small">The sum of squared errors SSE is:</p>

<div class="small">$$ SSE = \sum_{i=1}^{n} \epsilon_i^2 $$</div>

<div class="small">$$ = \sum_{i=1}^{n} \left[ (y_i - \bar{y}) + \hat{\beta}_1(x_i - \bar{x}) \right]^2 $$</div>

<div class="small">$$ = \sum_{i=1}^{n} \left[ (y_i - \bar{y})^2 + 2\hat{\beta}_1(y_i - \bar{y})(x_i - \bar{x}) + \hat{\beta}_1^2(x_i - \bar{x})^2 \right] $$</div>

<p class="smallest">Here, \(SSE\) represents the variability in the response variable that is not explained by the linear model.</p>

</div>

<div class="no-hang" data-fragment-index="1">

<p class="small">Differentiating this equation with respect to \(\hat{\beta}_1\), and equating the result to zero:</p>

<div class="small">$$ \frac{d(SSE)}{d\hat{\beta}_1} = -2s_{xy} + 2\hat{\beta}_1s_{x}^2 = 0 $$</div>

<p class="small">That is,</p>

<div class="small">$$ \hat{\beta}_1 = \frac{s_{xy}}{s_{x}^2} = \frac{\sum xy - n\bar{x}\bar{y}}{\sum x^2 - n(\bar{x})^2} $$</div>

</div>

<div class="framed border-info" style="grid-column:1/3;" data-fragment-index="2">

<p>

The slope \( \hat{\beta}_1 \) is derived by minimizing the sum of

squared errors (SSE) with respect to \( \hat{\beta}_1 \), leading

to the least squares estimates for the regression coefficients.

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

\( s_{xy} \) and \( s_{x}^2 \) represent the covariance of \(x\) and \(y\), and the variance of \(x\) respectively, and are used to solve for the slope \( \hat{\beta}_1 \).

</p>

</aside>

</section>



<!-- Slide 3: Allocation of Variation -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Allocation of Variation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns: 1fr 1fr; gap: 1vmin;">

<!-- Error Variance Without Regression -->

<div class="no-hang">

<p class="small">Error variance without Regression:</p>

<div class="smaller">$$ \text{Error} = e_i = y_i - \bar{y} $$</div>

<p class="small">Variance of Errors without regression:</p>

<div class="smallest">$$ \frac{1}{n - 1} \sum_{i=1}^{n} e_i^2 $$</div>

<div class="smallest">$$ = \frac{1}{n - 1} \sum_{i=1}^{n} (y_i - \bar{y})^2 $$</div>

<div class="smallest">$$ = \text{Variance of } y $$</div>

</div>

<!-- Total Sum of Squares (SST) -->

<div class="no-hang">

<p class="small">Total sum of squares (SST):</p>

<div class="smallest">$$ SST = \sum_{i=1}^{n} (y_i - \bar{y})^2 $$</div>

<div class="smallest">$$ = \left( \sum_{i=1}^{n} y_i^2 \right) - n\bar{y}^2 $$</div>

<div class="smallest">$$ = SSY - SSO $$</div>

<p class="smallest">Where \( SSY \) is the sum of squares of \( y \) and \( SSO \) is the sum of squares of \( \bar{y} \) equal to \( n\bar{y}^2 \).</p>

</div>

<!-- Sum of Squares due to Regression (SSR) -->

<div class="no-hang framed border-success fragment grid-generic" style="grid-column: 1/3;grid-template-columns: 1fr 1fr; gap: 1vmin;">

<p class="small">Sum of Squares due to Regression (SSR):</p>

<p class="small">Coefficient of Determination (\(R^2\)):</p>

<div class="smallest">$$ SSR = SST - SSE  = \sum(\hat{y}_i - \bar{y})^2$$</div>

<div class="smallest">$$ R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST} $$</div>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

SSR measures the amount of variability in the dependent variable that is explained by the independent variable(s) in a regression model. Conceptually, it quantifies how well the regression model fits the data compared to the mean model (which uses the mean of the dependent variable as the prediction for every observation)

</p>

<p>

Notes: This slide outlines how we allocate the variation in our data between the model and the errors. SST tells us the total variability in our dependent variable, \(y\), while SSR tells us how much of that variability is explained by our regression model. The difference, SSE, is the amount of variability not explained by the model. \(R^2\) gives us the proportion of the total variation that is explained by the model. It's an essential measure of how well our model fits the data.

</p>

</aside>

</section>



<section>

<div class="grid-wrapper">

<div class="header">

<h2>Uncertainty in $\hat{\beta}$ Estimates</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-auto-rows:auto;gap:5vmin;">

<!-- MSE Definition -->

<div class="small fragment sided border-info no-hang" data-fragment-index="1" style="grid-column:1/3;">

<p class="small">

We can relate the sampling distributions for the $\beta$ estimates ($\hat{\beta}$

is the estimator for the population $\beta$) by estimating standard error

of the regression from the variance of the residuals (<span class="em">Mean Squared Error</span>):

</p>

<p>$$ MSE = \frac{SSE}{n - p - 1} $$</p>

<p class="smallest">Recall \( SSE \) is the Sum of Squared Errors, $SSE = \sum (y_i - \hat{y})^2$, \( n \) is the number of observations, and \( p \) is the number of predictors (<span class="em">excluding</span> the intercept).</p>

<p class="smallest">

MSE is an estimate of the variance of the error term \( \epsilon \)

in the population model: $Y=\beta_0+\beta_1X+\epsilon$.

</p>

</div>

<!-- SE for Slope (b1) -->

<div class="fragment no-hang" data-fragment-index="2">

<p><span class="em">Standard Error of Slope \( \hat{\beta}_1 \):</span></p>

<div class="smallest">$$ SE(\hat{\beta}_1) = \sqrt{\text{Var}(\hat{\beta}_1)} = \sqrt{\frac{MSE}{\sum (x_i - \bar{x})^2}} $$</div>

<p class="smallest">The standard error of \( \hat{\beta}_1 \) quantifies the precision of the slope estimate. It's calculated as the square root of the variance of \( \hat{\beta}_1 \), which is derived from the mean of the squared deviations of our predictor \( x \) from its mean \( \bar{x} \), scaled by the MSE. This variance reflects how much the slope would vary across different samples from the same population.</p>

</div>

<!-- SE for Intercept (b0) -->

<div class="fragment no-hang" data-fragment-index="3">

<p><span class="em">Standard Error of Intercept \( \hat{\beta}_0 \):</span></p>

<div class="smallest">$$ SE(\hat{\beta}_0) = \sqrt{MSE \left(\frac{1}{n} + \frac{\bar{x}^2}{\sum (x_i - \bar{x})^2}\right)} $$</div>

<p class="smallest">The standard error of \( \hat{\beta}_0 \) represents the spread of the intercept's sampling distribution. The formula accounts for the average squared distance of \( x \) values from their mean, suggesting as this distance increases, or as the sample size \( n \) grows, our estimate of \( \hat{\beta}_0 \) becomes more precise.</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

Just like estimating the se of the mean (recall sqrt(var(x)/(n-1))), we

can estimate the standard error the beta coefficients by assessing the

spread of the residuals wrt to the prediction, and standardizing it.

</p>

<p>

That is, we take the SSE and standardize it by the variation in the x variable, or by scaling it with the average fractional variation in x.

</p>

<p>We don't need to memorize these formulas, but it's good to know they exist, as this is what we are constructing during the bootstrap process.</p>

</aside>

</section>



<section>

<div class="grid-wrapper">

<div class="header">

<h2>How Do We Minimize <span class="danger">Error</span>?</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr 1fr;grid-template-rows:1fr;gap:2vmin;">

<div class="small no-hang" style="text-align:left;font-size:90%;">

<p class="fragment" data-fragment-index="0">

Using Ordinary Least Squares (OLS), we minimized the average <span class="success">Squared Error</span>

($MSE_{(\beta_0,\beta_1)}$ or $\hat{\epsilon}$), such that

$$\widehat{\operatorname{MSE}}_{(\beta_0,\, \beta_1)} = \frac{1}{n}\sum_{i=1}^{n}\left( y_i - (\beta_0+\beta_1x_i)\right)^2$$

</p>

<p class="fragment" data-fragment-index="1">

That is, we found values for $\beta_0$ and $\beta_1$ that make $\hat{y}$ as

close to $\mathbb{E}X$ as possible.

</p>

<p class="fragment" data-fragment-index="2">

Conceptually, this is like checking a lot of possible values and combinations

for the $\beta$ coefficients and finding the smallest $\epsilon$.

</p>

<p class="fragment" data-fragment-index="3">

We find the intersection of Slope and Intercept at:

$$\begin{align}

\hat{\beta_1}=\frac{s_{xy}}{s^2_{x}},

\hat{\beta_0}=\overline{y}-\hat{\beta_1} \overline{x}.

\end{align}$$

</p>

</div>

<div class="full-width" style="justify-self:start;align-self:center;">

<svg width="100%" viewBox="410 90 400 300">

<use class="fragment" data-fragment-index="3" xlink:href="lib/img/OLS-min-lvdt.svg#axes_1"></use>

<use class="fragment" data-fragment-index="0" xlink:href="lib/img/OLS-min-lvdt.svg#grid3d_1"></use>

<use class="fragment" data-fragment-index="0" xlink:href="lib/img/OLS-min-lvdt.svg#grid3d_2"></use>

<use class="fragment" data-fragment-index="0" xlink:href="lib/img/OLS-min-lvdt.svg#grid3d_3"></use>

<use class="fragment" data-fragment-index="2" xlink:href="lib/img/OLS-min-lvdt.svg#axes_2"></use>

<use class="fragment" data-fragment-index="0" xlink:href="lib/img/OLS-min-lvdt.svg#axis3d_1"></use>

<use class="fragment" data-fragment-index="0" xlink:href="lib/img/OLS-min-lvdt.svg#axis3d_2"></use>

<use class="fragment" data-fragment-index="0" xlink:href="lib/img/OLS-min-lvdt.svg#axis3d_3"></use>

</svg>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>Point out the residual calctulation inside mse formula.</p>

<p>

Recall, what is error? The standardized area (distance) of the deviations between some point and some model.

</p>

<p>

It turns out, that if you follow the derivation, the minimum of $(y_i-a)^2$ is simply $\mathbb{E}[X|Y=y]$.

</p>

</aside>

</section>



<section>

<div class="grid-wrapper">

<div class="header">

<h2>Linear Modeling</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-template-rows:1fr;gap:5px;">

<div style="width:80%;height:100%;">

<svg width="100%" viewBox="0 0 504 259.2">

<use xlink:href="lib/img/regression-train-test-sets-split.svg#layer0"></use>

<use class="fragment" xlink:href="lib/img/regression-train-test-sets-split.svg#layer1"></use>

<use class="fragment" xlink:href="lib/img/regression-train-test-sets-split.svg#layer2"></use>

<use class="fragment" xlink:href="lib/img/regression-train-test-sets-split.svg#layer3"></use>

<use class="fragment" xlink:href="lib/img/regression-train-test-sets-split.svg#layer4"></use>

<use class="fragment" xlink:href="lib/img/regression-train-test-sets-split.svg#layer5"></use>

</svg>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>

Keep in mind, when we build a linear model, it is usually with the purpose

of predicting some new measurements. Why have a model if you don't use it to

model a process?

</p>

</aside>

</section>



<!-- Let's make a prediction model -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Example Usage</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-template-rows:1fr;gap:5px;height:100%;justify-items:center;">

<vizzy data-src="lib/interactives/linear-regression-prediction-model.html" style="width:50%;height:100%;"></vizzy>

</div>

</div>

</div>

<aside class="notes">

<p>Get A shoe size from the students, show how using a model to predict new data (within the domain).</p>

</aside>

<!-- </section> -->
        </section>
        <section>
          <!-- The Model -->

<!-- <section> -->

<div class="grid-wrapper">

<div class="header">

<h2>Evaluating The Model</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<p class="smaller">

It is important evaluate the "Goodness of Fit", 3 common statistics we use are:

</p>

<ul class="small">

<li>

The <span class="pop">$R^2$</span>, or <span class="em strong">coefficient of determination</span>

</li>

<li>

The <span class="pop">$RMSE$</span>, or <span class="em strong">Root Mean Square Error</span>

</li>

<li>

The <span class="orange">$F$-statistic</span>

</li>

</ul>

<p class="small down-2 em u">

All three statistics are based on two sums of squares:

</p>

<table class="smaller down-2">

<col width=50%>

<col width=50%>

<tbody>

<tr>

<td class="bg-info-light">Total Sum of Squares ($TSS$)</td>

<td class="bg-danger-light">Sum of Squares Error ($SSE$)</td>

</tr>

<tr class="border-bottom">

<td>

Measures "distance" from the data to the mean ($\bar{y}$).

$TSS=\sum_{i=1}^{n}(y_i-\bar{y})^2$

</td>

<td>

Measures "distance" from the data to model ($\hat{y}$).

$SSE=\sum_{i=1}^{n}(y_i-\hat{y})^2$

</td>

</tr>

</tbody>

</table>

<p class="small">

<i class="fas fa-arrow-circle-right"></i>

Different combinations of these two values provide different information about how the regression model

compares to the mean model.

</p>

</div>

</div>

</div>

</section>



<!-- R squared -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Coefficient Of Determination, $R^2$</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<p class="framed border-pink">

$R^2$ measures the percentage of total variation

in the response variable that is explained by the linear relationship.

</p>

<p>

<span class="pink">$R^2=1-\frac{\textrm{Sum of squared errors (SSE)}}{\textrm{Total sum of squares (TSS)}}$</span>

$= 1-\frac{\sum_{i=1}^{n}(y_i-\hat{y})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2}$

</p>

<p class="u em muted down-3">

Notes:

</p>

<ul class="small">

<li>

For <span class="danger">Linear Models</span>, $R^2$is the

<span class="orange">square of the correlation coefficient</span> ($r$)

<i class="fas fa-arrow-right"></i> $R^2 = r^2$

</li>

<li>

The slope ($m$) of the regression line tells you how much change in $Y$ you can

expect based on a given change in $X$. The coefficient $R^2$ tells you

<span class="orange strong">how much of the variation in $Y$ is attributable to (explained by) the variation in $X$</span>.

The rest of the variation (or <span class="em danger">"noise"</span>), is accounted by other factors,

such as measurement error, individual variation, etc.

</li>

</ul>

</div>

</div>

</div>

</section>



<!-- RMSE -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Root mean square error, $RMSE$</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<p class="framed border-pink">

The $RMSE$ measures how close the observed data points are to the model's predicted values.

</p>

<p>

The $RMSE$ evaluates the model performance, and computes the square

root of the average squared residual (distance from the data to the model).

</p>

<p class="pink">

$RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y})^2}$

</p>

<p class="smaller down-3">

<i class="fas fa-arrow-circle-right orange"></i>

The key idea behind the computation of the $RMSE$

is that predictions ($\hat{y}$) that are <span class="orange">far away from the true observed data</span>

value ($y$) will contribute more heavily to <span class="orange">increasing the value of the $RMSE$</span>

than predictions that are close to the true values.

</p>

<p class="down-2">

<i class="fas fa-arrow-circle-right orange"></i>

<span class="orange">Lower</span> values of RMSE indicate <span class="orange">better</span> fit.

</p>

</div>

</div>

</div>

</section>



<!-- COMPARISON -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2>Model evaluation, $R^2$ vs $RMSE$</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<div>

<table class="small">

<col width=50%>

<col width=50%>

<tbody>

<tr>

<td class="bg-info-light center">$R^2$</td>

<td class="bg-danger-light center">$RMSE$</td>

</tr>

<tr>

<td>Square of the correlation coefficient</td>

<td>Square root of the average squared residual</td>

</tr>

<tr>

<td colspan="2" class="center">Both give an indication about the

<span class="em">"goodness of the fit"</span></td>

</tr>

<tr>

<td>$R^2$ is conveniently scaled between 0 and 1 (<span class="info">relative measure</span> of fit)</td>

<td>$RMSE$ is not scaled to any particular value (<span class="danger">absolute measure</span> of fit)</td>

</tr>

<tr>

<td>$R^2$ can be more easily interpreted

in the <span class="info">context of the linear association</span>

analyzed

(how successful the fit is in explaining the variation of the data)

</td>

<td>$RMSE$ explicitly provides information about

<span class="danger">how much our predictions deviate, on average</span>,

from the actual values in the dataset</td>

</tr>

<tr>

<td>Its main purpose is either the <span class="info">prediction</span>

of future outcomes or the <span class="info">testing</span> of hypotheses.</td>

<td>

It is one of the most important criterion for fit if the main purpose of the

model is <span class="danger">prediction</span>

</td>

</tr>

</tbody>

</table>

</div>

</div>

</div>

</div>

</section>
        </section>
        <section data-background-image="lib/img/bg-regression-olympics-abstract.webp" data-background-size="cover" id="section-title-3">
          <div class="grid-wrapper">
            <div class="section-title-content" id="section-content-3">
              <div class="section-number">
                <span class="large-number">
                  3
                </span>
              </div>
              <div class="headlines">
                <h2 class="r-fit-text">
                  Linear Regression
                </h2>
                <h3>
                  Cautionary Discretion
                </h3>
              </div>
            </div>
          </div>
          <style>

#section-content-3.section-title-content {

background-color: rgba(240, 240, 240, 0.6) !important;

border-radius: 2rem !important;

box-shadow: 0 0 2rem 2rem rgba(240, 240, 240, 0.6) !important;

}

</style>

<aside class="notes">

<p>Section Notes</p>

</aside>

</section> <!-- End section title -->



<!-- Caution 1: Extrapolation -->

<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2><i class="fas fa-exclamation-triangle fa-2x danger"></i> Extrapolation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<p class="small">

The regression line should only be used to

<span class="strong">predict values within or close to those contained in the dataset</span>.

Far beyond the dataset, the trend may change and the predictions will be incorrect.

</p>

<div class="grid-generic" style="grid-template-columns:3fr 1fr;grid-template-rows:1fr;gap:5px;width:70%;">

<div><img class="framed" src="lib/img/regression-olympics-100m-nature-paper.png" width=100%></div>

<p class="em" style="font-size:75%;">

Nature 431, 525 (30 September <span class="warning">2004</span>)

</p>

</div>

</div>

</div>

</div>

</section>

<!-- Caution 1: Extrapolation -->

<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2><i class="fas fa-exclamation-triangle fa-2x danger"></i> Extrapolation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<p class="small">

The regression line should only be used to

<span class="strong">predict values within or close to those contained in the dataset</span>.

Far beyond the dataset, the trend may change and the predictions will be incorrect.

</p>

<div class="grid-generic" style="grid-template-columns:2fr 1fr;grid-template-rows:1fr;gap:5px;">

<div><img class="framed" src="lib/img/regression-olympics-times-100m.svg" width=100%></div>

<div class="small">

<p class="em" style="font-size:75%;">

Nature 431, 525 (30 September <span class="warning">2004</span>)

</p>

<p class="quoted">

Projections intersect just before 2156 Olympics, where winning women's 100m sprint time of 8.079s will be faster than the men's at 8.098s.

</p>

<p>

At this rate, women will reach a 0s 100m sprint time in 2643, 200+ years before men, who will achieve this feat in 2892!

</p>

</div>

</div>

</div>

</div>

</div>

</section>

<!-- Caution 1: Extrapolation -->

<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2><i class="fas fa-exclamation-triangle fa-2x danger"></i> Extrapolation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<p class="small">

The regression line should only be used to

<span class="strong">predict values within or close to those contained in the dataset</span>.

Far beyond the dataset, the trend may change and the predictions will be incorrect.

</p>

<div class="grid-generic" style="grid-template-columns:3fr 1fr;grid-template-rows:1fr;gap:5px;width:80%;">

<div>

<svg width="100%" viewBox="0 0 504 288">

<use class="fragment current-visible" data-fragment-index=1 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_2"></use>

<use class="fragment current-visible" data-fragment-index=2 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_2"></use>

<use class="fragment current-visible" data-fragment-index=3 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_2"></use>

<use class="fragment current-visible" data-fragment-index=4 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_2"></use>

<use class="fragment current-visible" data-fragment-index=5 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_2"></use>

<use class="fragment current-visible" data-fragment-index=6 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_2"></use>

<use xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_1"></use>

<use class="fragment" data-fragment-index=2 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_3"></use>

<use class="fragment" data-fragment-index=3 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_4"></use>

<use class="fragment" data-fragment-index=4 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_5"></use>

<use class="fragment" data-fragment-index=5 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_6"></use>

<use class="fragment" data-fragment-index=6 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_7"></use>

<use class="fragment" data-fragment-index=7 xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_8"></use>

</svg>

</div>

<div style="font-size:80%;">

<table class="smaller">

<col width=30%>

<col width=35%>

<col width=35%>

<tbody>

<tr class="bg-pink-light black">

<td>Year</td>

<td>Predicted</td>

<td>Real</td>

</tr>

<tr>

<td>2008</td>

<td>10.58</td>

<td><span class="fragment success" data-fragment-index=2>10.78</span></td>

</tr>

<tr>

<td>2012</td>

<td>10.51</td>

<td><span class="fragment success" data-fragment-index=3>10.75</span></td>

</tr>

<tr>

<td>2016</td>

<td>10.44</td>

<td><span class="fragment success" data-fragment-index=4>10.71</span></td>

</tr>

<tr>

<td>2020</td>

<td>10.38</td>

<td><span class="fragment success" data-fragment-index=5>10.61</span></td>

</tr>

<tr>

<td>2024</td>

<td>10.31</td>

<td><span class="fragment success" data-fragment-index=6>10.72</span></td>

</tr>

<tr class="bg-info-light black">

<td>Year</td>

<td>Predicted</td>

<td>Real</td>

</tr>

<tr>

<td>2008</td>

<td>9.73</td>

<td><span class="fragment danger" data-fragment-index=2>9.69</span></td>

</tr>

<tr>

<td>2012</td>

<td>9.68</td>

<td><span class="fragment danger" data-fragment-index=3>9.63</span></td>

</tr>

<tr>

<td>2016</td>

<td>9.64</td>

<td><span class="fragment danger" data-fragment-index=4>9.81</span></td>

</tr>

<tr>

<td>2020</td>

<td>9.60</td>

<td><span class="fragment danger" data-fragment-index=5>9.80</span></td>

</tr>

<tr>

<td>2024</td>

<td>9.55</td>

<td><span class="fragment danger" data-fragment-index=6>9.79</span></td>

</tr>

</tbody>

</table>

</div>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>Keep in mind this is sarcasm, don't do this, but if you're trying to predict the future:</p>

<p>Men will reach 0s 100m dash in 2892</p>

<p>Women will reach 0s 100m dash in 2643</p>

<p>Men (updated) will reach 0s 100m dash in 2960 (as low as 2844)</p>

<p>Women (updated) will reach 0s 100m dash in 2784 (as low as 2640)</p>

</aside>

</section>

<!-- Caution 1: Extrapolation -->

<section data-auto-animate>

<div class="grid-wrapper">

<div class="header">

<h2><i class="fas fa-exclamation-triangle fa-2x danger"></i> Extrapolation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<p class="small">

The regression line should only be used to

<span class="strong">predict values within or close to those contained in the dataset</span>.

Far beyond the dataset, the trend may change and the predictions will be incorrect.

</p>

<div class="grid-generic" style="grid-template-columns:2fr 1fr;grid-template-rows:1fr;gap:5px;width:100%;">

<div>

<svg width="100%" viewBox="0 0 504 288">

<use xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_1"></use>

<use xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_2"></use>

<use xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_3"></use>

<use xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_4"></use>

<use xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_5"></use>

<use xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_6"></use>

<use xlink:href="lib/img/regression-olympics-winning-times-100m-fig-2024.svg#axes_7"></use>

</svg>

</div>

<p class="small">

"A. J. Tatem and colleagues calculate that women may out-sprint men by the middle of the twenty-second century.

They omit to mention, however, that (according to their analysis)

<span class="pop">a far more interesting race should occur in about 2636,

when times of less than zero seconds will be recorded</span>."

<br>

<span class="em">-- Kenneth Rice (2004) --</span>

</p>

</div>

</div>

</div>

</div>

<aside class="notes">

<p>So the data from the last few years indicates we'll have a sub-zero sprint time even sooner! 2608</p>

<p>Keep in mind this is sarcasm, don't do this, but if you're trying to predict the future:</p>

<p>Men will reach 0s 100m dash in 2892</p>

<p>Women will reach 0s 100m dash in 2643</p>

<p>Men (updated) will reach 0s 100m dash in 2960 (as low as 2844)</p>

<p>Women (updated) will reach 0s 100m dash in 2784 (as low as 2640)</p>

</aside>

</section>



<!-- Caution 2: Generalization -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2><i class="fas fa-exclamation-triangle fa-2x danger"></i> Generalization</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:2vmin;">

<p>

<i class="fas fa-arrow-circle-right red"></i>

A regression model developed from a specific dataset <span class="strong">should not be used to

generalize about observational units not related to the original dataset</span>

or to conclude about the general pattern of the phenomena.

</p>

<p class="fragment">

<i class="fas fa-arrow-circle-right info"></i>

If you develop a linear model from data collected on a

specific sport team in order to predict how this team will

perform in the near future, <span class="info">it is unlikely that the same

model would be able to accurately predict how all the other

teams will perform</span>. Although we may find some kind of

relationship between the variable recorded on the team we

are studying, the same relationships might not exist for

another team.

</p>

</div>

</div>

</div>

</section>



<!-- Causation -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2><i class="fas fa-exclamation-triangle fa-2x danger"></i> Causation</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:2vmin;">

<p>

<i class="fas fa-arrow-circle-right red"></i>

Although we imply a causal relationship when we use

linear regression, <span class="strong">regression analysis

will not prove

causality between two variables</span>.

</p>

<p class="fragment" data-fragment-index=1>

<i class="fas fa-arrow-circle-right info"></i>

Recall that linear regression is a

<span class="info">strictly numeric procedure</span>; you may

find that two totally unrelated variables give a significant $R^2$.

</p>

<p class="fragment" data-fragment-index=1>

<i class="fas fa-arrow-circle-right info"></i>

We must have some understanding of the phenomenon of interest in order to

<span class="info strong">interpret the results appropriately</span>.

</p>

</div>

</div>

</div>

</section>



<!-- Validity -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2><i class="fas fa-exclamation-triangle fa-2x danger"></i> Validity</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:2vmin;">

<p>

<i class="fas fa-arrow-circle-right red"></i>

Although we imply a causal relationship when we use

linear regression, <span class="strong">regression analysis

will not prove

causality between two variables</span>.

</p>

<div class="grid-generic" style="grid-template-columns:4fr 5fr;grid-template-rows:1fr;gap:1vmin;width:80%">

<div style="font-size:65%;text-align:center;">

<table>

<thead>

<tr>

<th class="bg-muted border-right" colspan="2">Set #1</th>

<th class="bg-muted border-right" colspan="2">Set #2</th>

<th class="bg-muted border-right" colspan="2">Set #3</th>

<th class="bg-muted border-right" colspan="2">Set #4</th>

</tr>

</thead>

<tbody>

<tr>

<td>x</td>

<td class="border-right">y</td>

<td>x</td>

<td class="border-right">y</td>

<td>x</td>

<td class="border-right">y</td>

<td>x</td>

<td>y</td>

</tr>

<tr>

<td>10</td>

<td class="border-right">8.04</td>

<td>10</td>

<td class="border-right">9.14</td>

<td>10</td>

<td class="border-right">7.46</td>

<td>8</td>

<td>6.58</td>

</tr>

<tr>

<td>8</td>

<td class="border-right">6.95</td>

<td>8</td>

<td class="border-right">8.14</td>

<td>8</td>

<td class="border-right">6.77</td>

<td>8</td>

<td>5.76</td>

</tr>

<tr>

<td>13</td>

<td class="border-right">7.58</td>

<td>13</td>

<td class="border-right">8.74</td>

<td>13</td>

<td class="border-right">12.74</td>

<td>8</td>

<td>7.71</td>

</tr>

<tr>

<td>9</td>

<td class="border-right">8.81</td>

<td>9</td>

<td class="border-right">8.77</td>

<td>9</td>

<td class="border-right">7.11</td>

<td>8</td>

<td>8.84</td>

</tr>

<tr>

<td>11</td>

<td class="border-right">8.33</td>

<td>11</td>

<td class="border-right">9.26</td>

<td>11</td>

<td class="border-right">7.81</td>

<td>8</td>

<td>8.47</td>

</tr>

<tr>

<td>14</td>

<td class="border-right">9.96</td>

<td>14</td>

<td  class="border-right">8.1</td>

<td>14</td>

<td class="border-right">8.84</td>

<td>8</td>

<td>7.04</td>

</tr>

<tr>

<td>6</td>

<td class="border-right">7.24</td>

<td>6</td>

<td class="border-right">6.13</td>

<td>6</td>

<td class="border-right">6.08</td>

<td>8</td>

<td>5.25</td>

</tr>

<tr>

<td>4</td>

<td class="border-right">4.26</td>

<td>4</td>

<td class="border-right">3.1</td>

<td>4</td>

<td class="border-right">5.39</td>

<td>19</td>

<td>12.5</td>

</tr>

<tr>

<td>12</td>

<td class="border-right">10.84</td>

<td>12</td>

<td class="border-right">9.13</td>

<td>12</td>

<td class="border-right">8.15</td>

<td>8</td>

<td>5.56</td>

</tr>

<tr>

<td>7</td>

<td class="border-right">4.82</td>

<td>7</td>

<td  class="border-right">7.26</td>

<td>7</td>

<td  class="border-right">6.42</td>

<td>8</td>

<td>7.91</td>

</tr>

<tr>

<td>5</td>

<td  class="border-right">5.68</td>

<td>5</td>

<td  class="border-right">4.74</td>

<td>5</td>

<td class="border-right">5.73</td>

<td>8</td>

<td>6.89</td>

</tr>

</tbody>

</table>

</div>

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:5px;">

<div style="font-size:70%;">

<table class="smaller up-5">

<tbody>

<tr class="bg-warning-light">

<td>Correlation</td>

<td>0.86</td>

</tr>

<tr class="bg-info-light">

<td>Regression line</td>

<td>y = 3 + 0.5x</td>

</tr>

</tbody>

</table>

</div>

<div>

<svg width="100%" viewBox="0 0 432 324">

<use xlink:href="lib/img/anscombe.svg#axes_1"></use>

<use xlink:href="lib/img/anscombe.svg#axes_2"></use>

<use xlink:href="lib/img/anscombe.svg#axes_3"></use>

<use xlink:href="lib/img/anscombe.svg#axes_4"></use>

<use class="fragment" data-fragment-index=2 xlink:href="lib/img/anscombe.svg#axes_5"></use>

<use class="fragment" data-fragment-index=2 xlink:href="lib/img/anscombe.svg#axes_6"></use>

<use class="fragment" data-fragment-index=2 xlink:href="lib/img/anscombe.svg#axes_7"></use>

<use class="fragment" data-fragment-index=2 xlink:href="lib/img/anscombe.svg#axes_8"></use>

</svg>

</div>

</div>

</div>

</div>

</div>

</div>

</section>



<!-- Resistance -->

<section>

<div class="grid-wrapper">

<div class="header">

<h2><i class="fas fa-exclamation-triangle fa-2x danger"></i> Resistance</h2>

</div>

<div class="content">

<div class="grid-generic" style="grid-template-columns:1fr;grid-auto-rows:auto;gap:2vmin;">

<p>

<i class="fas fa-arrow-circle-right red"></i>

<span class="strong">Outliers can have a strong influence</span> on the regression line

(similarly to what we saw for correlation). Lots of robust

linear regression algorithms are capable of dealing with

outliers by giving them less weight in the residual minimization function.

</p>

<div class="grid-generic" style="grid-template-columns:1fr 1.2fr;grid-template-rows:1fr;gap:5px;">

<div>

<p class="small">

<i class="fas fa-arrow-circle-right info"></i>

In particular, data points for which the

<span class="info">explanatory value (x) is an outlier</span> are often

called <span class="danger u-danger">influential</span> points because they exert an

<span class="info">overly strong effect</span> on the regression line.

</p>

</div>

<div>

<img src="lib/img/regression-outliers.svg" width=100%>

</div>

</div>

</div>

</div>

</div>



<!-- </section> -->
        </section>
      </div>
      <footer class="main-footer">
        <span>
          Lecture 13
        </span>
        <span style="text-align:center;">
        </span>
        <span style="text-align:right;">
          <a href="https:\\khrisgriffis.com" target="_blank" rel="noopener noreferrer">Khris Griffis &#169;2025</a>
        </span>
      </footer>
    </div>
    <script src="./src/reveal.js">
    </script>
    <script src="./src/plugin/notes/notes.js">
    </script>
    <script src="./src/plugin/highlight/highlight.js">
    </script>
    <script src="./src/plugin/math/math.js">
    </script>
    <script src="./src/plugin/reveal-splash/reveal-splash.js">
    </script>
    <script src="./src/plugin/vizzy-reveal/vizzy.js">
    </script>
    <script>
      Reveal.initialize({
autoSlide: 0,
center: true,
controls: true,
controlsBackArrows: "faded",
controlsLayout: "bottom-right",
display: "block",
fragments: true,
fragmentInURL: true,
hash: true,
hideCursorTime: 5000,
keyboard: true,
mobileViewDistance: 3,
mouseWheel: false,
navigationMode: "linear",
overview: true,
pdfMaxPagesPerSlide: 1,
pdfSeparateFragments: false,
preloadIframes: null,
progress: false,
showNotes: false,
showSlideNumber: "print",
sortFragmentsOnSync: true,
touch: true,
transition: "fade",
transitionSpeed: "default",
viewDistance: 3,
backgroundTransition: "fade",
controlsTutorial: false,
embedded: false,
help: true,
hideInactiveCursor: true,
history: false,
loop: false,
previewLinks: false,
rtl: false,
shuffle: false,
slideNumber: false,
width: 1920,
height: 1080,
margin: 0.081,
minScale: 0.06,
maxScale: 1.57,
mathjax3: {
mathjax: "https://cdn.jsdelivr.net/npm/mathjax@4.0.0-beta.7/tex-mml-chtml.js",
loader: {
load: [
"[tex]/html",
],
},
tex: {
packages: {
'[+]': [
"html",
],
},
inlineMath: [
["$", "$"],
["\\(", "\\)"],
],
processEscapes: true,
processEnvironments: true,
},
options: {
skipHtmlTags: [
"script",
"noscript",
"style",
"textarea",
"pre",
],
},
chtml: {
scale: 0.8,
minScale: 0.4,
},
Safe: {
sizeMin: 0.4,
sizeMax: 1.25,
},
output: {
displayOverflow: "linebreak",
linebreaks: {
inline: true,
width: "100%",
lineleading: 0.2,
LinebreakVisitor: null,
},
},
},
notes: {

},
highlight: {

},
vizzy: {
autoRunTransitions: true,
autoTransitionDelay: 100,
devMode: false,
onSlideChangedDelay: 0,
},
splash: {
splashImage: "lib/img/ps200_logo.svg",
text: "Welcome to PS200!",
minimumDisplay: 2,
},
plugins: [RevealNotes, RevealHighlight, RevealMath.MathJax3, Splash, Vizzy]
});
    </script>
  </body>
</html>
